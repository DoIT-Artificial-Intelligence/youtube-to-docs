# How This Works

`youtube-to-docs` automates the conversion of YouTube videos into structured documentation and multimodal assets. This document explains the technical workflow and core components of the system.

## System Architecture

The tool operates as a pipeline that ingests YouTube content, processes it through various AI models, and outputs structured data and files.

### 1. Input Resolution
The entry point (`youtube_to_docs/main.py`) accepts flexible inputs:
- **Video IDs**: Direct processing.
- **Playlists**: Resolves all video IDs within a playlist.
- **Channels**: Resolves a channel's "Uploads" playlist to process all their videos.

**Key Component**: `youtube_to_docs.transcript.resolve_video_ids` uses the YouTube Data API to fetch lists of videos when a Playlist or Channel is provided.

    *   **AI Source**: If specified, an AI model (like Gemini 3 Flash) processes the extracted audio file to generate a fresh, potentially higher-accuracy transcript.
    *   **SRT Generation**: For both YouTube and AI sources, the system generates an `.srt` file. This is crucial for accessibility and provides the raw timing data used for precision Q&A alignment.

> **Note on Auto-Captions**: Automatic captions are generated by speech recognition and may have accuracy issues. They are not always immediately available.

### 3. The LLM Pipeline
Text processing is handled by Large Language Models (LLMs) defined in `youtube_to_docs/llms.py`. The pipeline is model-agnostic, supporting Google Gemini, Vertex AI, AWS Bedrock, and Azure Foundry.

For each video, the specified model performs three distinct tasks:

1.  **Speaker Extraction**:
    *   **Input**: Full transcript.
    *   **Task**: Identify speakers and their professional titles/roles.
    *   **Output**: A structured list (e.g., "Speaker 1 (Host)").

2.  **Q&A Generation**:
    *   **Input**: Full transcript + Identified Speakers + **Timing Reference (SRT)**.
    *   **Task**: Extract key questions and answers discussed in the video.
    *   **Precision Timing**: If YouTube SRT is available, it is passed to the LLM as a "Timing Reference". The model uses this to align the high-quality speech identification of the AI transcript with the pinpoint accuracy of YouTube's timing.
    *   **Output**: A Markdown table with columns for Questioner, Question, Responder, Answer, Timestamp, and **Timestamp URL**.

3.  **Summarization**:
    *   **Input**: Full transcript + Video Metadata.
    *   **Task**: Create a concise, comprehensive summary of the content.
    *   **Output**: A Markdown-formatted summary.

4.  **Tag Generation**:
    *   **Input**: Full transcript.
    *   **Task**: Generate up to 5 comma-separated tags for the transcript.
    *   **Output**: A comma-separated string of tags.

4.  **Multi-Language Support**:
    *   The tool supports processing videos in multiple languages via the `--language` argument.
    *   It iterates through each requested language, fetching or generating transcripts, summaries, Q&A, and infographics for that specific language.
    *   File names and column headers are suffixed with the language code (e.g., `(es)`) to keep assets organized.

### 5. Multimodal Generation
Beyond text, the tool creates audio and visual assets:

- **Text-to-Speech (TTS)**:
    *   Uses models (like Gemini's TTS) to convert the generated summary into an audio file.
    *   This allows users to "listen" to the video summary.

- **Infographics**:
    *   Uses image generation models to create a visual representation of the summary.
    *   **Supported Providers**:
        *   **Google**: Gemini, Imagen.
        *   **AWS Bedrock**: Titan Image Generator, Nova Canvas (requires `AWS_BEARER_TOKEN_BEDROCK`).
        *   **Azure Foundry**: GPT Image models (requires `AZURE_FOUNDRY_ENDPOINT` and `AZURE_FOUNDRY_API_KEY`).
    *   The prompt includes the video title and the generated summary text to ensure relevance.
- **Multimodal Alt Text**:
    *   Once an infographic is generated, an AI model processes the image bytes directly to generate descriptive alt text.
    *   **Post-processing**: The tool automatically strips common prefixes like "Alt text: " to ensure the output is clean and ready for accessibility use.
    *   This ensures infographics are accessible and searchable.

- **Video Generation**:
    *   Combines the generated infographic (visual) and TTS audio (sound) into a single MP4 video file.
    *   Uses `static-ffmpeg` to perform the merging, ensuring no external FFmpeg installation is required.
    *   This provides a shareable "video summary" format.

### 6. Cost Tracking
The system includes a pricing engine (`youtube_to_docs/prices.py`) that tracks token usage for every API call.
- It calculates costs for input and output tokens based on the specific model used.
- Costs are aggregated for speaker extraction, Q&A, summarization, and infographic generation.
- These estimates are saved directly into the output CSV.

## Data Organization

The final output is a structured CSV file (managed via `polars`) containing metadata, file paths, and AI outputs. Corresponding files are organized into subdirectories within a central artifacts folder:

```text
youtube-to-docs-artifacts/
├── youtube-docs.csv              # The main data file
├── transcript-files/             # Raw text transcripts (single long strings)
├── srt-files/                    # Standardized SRT transcript files
├── audio-files/                  # Extracted audio files (for AI transcription)
├── speaker-extraction-files/     # Identified speakers lists
├── qa-files/                     # Markdown Q&A tables with timestamps
├── summary-files/                # Markdown summaries
├── one-sentence-summary-files/   # Concisely summarized content
├── tag-files/                    # AI-generated tags files
├── infographic-files/            # Generated infographic images
├── alt-text-files/               # Multimodal alt text for infographics
└── video-files/                  # Combined infographic + audio videos
```

This structure ensures that while the CSV provides a high-level data view, the actual content is easily accessible as standalone files.